# Тестирование дисков

В Terraform сценарии проводится тестирование дисков Compute в Yandex Cloud (в скобках указаны размеры дисков):
- local-ssd (2,91 ТБ)
- network-ssd-io-m3 (1209 ГБ)
- network-ssd (1280 ГБ)
- network-ssd-nonreplicated (1302 ГБ)

Для каждого типа сетевого диска выбран размер в соответствие с необходимым количеством блоков размещения, после которого уже производительность диска будет ограничена [лимитами на диск](https://cloud.yandex.ru/ru/docs/compute/concepts/limits#compute-limits-disks).

## Детали методики тестирования

- Конфигурация тестовой ВМ: Intel Ice Lake, 10vCPU, 10GB RAM, [AlmaLinux 9](https://cloud.yandex.ru/ru/marketplace/products/yc/almalinux-9)
- Зона доступности `ru-central1-a`
- Размер блоков для сетевых дисков: 4 КБ
- Размер блоков для local-ssd: 512 байт
- Файловая система для тестовых дисков `ext4`, размер блока 4 КБ
- В начале тестов запускается серия тестов всех дисков, в которой для каждого типа диска создается своя тестовая ВМ с диском
- Для тестирования local-ssd создается новая группа выделенных хостов с одним хостом и тестовая ВМ размещается на этом хосте
- После завершения серии тестов дисков все созданные ресурсы в облаке удаляются
- Через заданный интервал запускается следующая серия тестов до тех пор, пока не завершится необходимое количество запусков серий

### Профиль тестовой нагрузки для одной серии тестов диска

Случайное чтение:
```bash
sudo fio --filename=/app/fiotest.dat --rw=randread --size=xx --ioengine=libaio --bs=8k --iodepth=256 --numjobs=1 --runtime=120 --group_reporting --direct=1 --name=random-read
```

Случайная запись:
```bash
sudo fio --filename=/app/fiotest.dat --rw=randwrite --size=xx --ioengine=libaio --bs=8k --iodepth=256 --numjobs=1 --runtime=120 --group_reporting --direct=1 --name=random-write
```

Значение для `--size` определяется необходимым процентом заполнения диска тестовым файлом во время первого теста `randread`. Процент заполнения диска во время теста можно указать в переменной `disk_fill_percent` в `variables.tf`. По умолчанию это значение 10%. При значении 90% время подготовки к началу тестирования в зависимости от типа диска может достигать 25-45 мин. Чем меньше значение заполнения диска, тем быстрее выполняется подготовка к запуску тестов. 


## Последовательность для запуска тестирования

1. Измените в `terraform.tfvars` значения для переменных: `folder_id` и `trusted_ip_for_access` (публичные IP-адреса, с которых будет разрешен доступ по SSH к тестовым ВМ). Также добавьте при необходимости ваши значения других переменных в `terraform.tfvars`, если они отличаются от значений по умолчанию в `variables.tf`. 
1. Запустите автоматическое тестирование серии тестов всех дисков (5 серий в примере) с интервалом между тестами (1 ч в примере):
    ```bash
    for i in 1 2 3 4 5; do terraform apply -auto-approve ; sleep 1m ; terraform destroy -auto-approve; sleep 1h ; done
    ```
1. После завершения серий тестов результаты fio тестов в json формате будут находиться в папке `results`. Все результаты тестов можно собрать в один Excel файл для последующего анализа с помощью скрипта `fio-parser.py`, который создаст в корневой папке проекта файл `fio-summary.xlsx` со значениями IOPS, BW и latency (slat + clat) для всех тестов:
    ```bash
    python3 fio-parser.py
    ```